{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6246a57b-5c38-410c-979d-3c733c701fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in /opt/anaconda3/lib/python3.11/site-packages (1.24.14)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fe2fd83-1bf0-4858-aa20-da0b5b0d4ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251805d-471d-469b-8d66-147716a02fac",
   "metadata": {},
   "source": [
    "# Extract Text From Allergy Report PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ab01f00-986f-4fa1-af64-3b8756394dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from PDF...\n",
      "Processing text...\n",
      "\n",
      "Ingredient Counts by Level:\n",
      "Level\n",
      "LEVEL 3    168\n",
      "LEVEL 1    143\n",
      "LEVEL 2    137\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Extracted Data:\n",
      "       Level Food Type        Ingredient\n",
      "0    LEVEL 1       Fat     Sunflower Oil\n",
      "1    LEVEL 2     Dairy  Cheese (cheddar)\n",
      "2    LEVEL 3       Fat     Vegetable Oil\n",
      "3    LEVEL 3         -                  \n",
      "4    LEVEL 3     Dairy  Cheese (cottage)\n",
      "..       ...       ...               ...\n",
      "443  LEVEL 1         -                  \n",
      "444  LEVEL 3         -                  \n",
      "445  LEVEL 2         -                  \n",
      "446  LEVEL 1         -                  \n",
      "447  LEVEL 1         -                  \n",
      "\n",
      "[448 rows x 3 columns]\n",
      "Results saved to /Users/ireneliu/Desktop/ingredients_analysis.csv.\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Function to process extracted text\n",
    "def process_text(text):\n",
    "    results = []\n",
    "    lines = text.split(\"\\n\")\n",
    "    current_level = None\n",
    "\n",
    "    for line in lines:\n",
    "        # Check for level markers\n",
    "        level_match = re.match(r\"(LEVEL \\d+)\", line)\n",
    "        if level_match:\n",
    "            current_level = level_match.group(1)\n",
    "        elif current_level:\n",
    "            # Extract food type and ingredient\n",
    "            match = re.match(r\"(.*)- (.*)\", line)\n",
    "            if match:\n",
    "                food_type = match.group(1).strip()\n",
    "                ingredient = match.group(2).strip()\n",
    "                LEVELS[current_level].append(ingredient)\n",
    "                results.append({\"Level\": current_level, \"Food Type\": food_type, \"Ingredient\": ingredient})\n",
    "    return results\n",
    "\n",
    "# Main script\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with the path to your PDF file\n",
    "    pdf_path = \"/Users/ireneliu/Desktop/Level info.pdf\"\n",
    "    print(\"Extracting text from PDF...\")\n",
    "    pdf_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    print(\"Processing text...\")\n",
    "    extracted_data = process_text(pdf_text)\n",
    "\n",
    "    # Convert to DataFrame for easy analysis\n",
    "    df = pd.DataFrame(extracted_data)\n",
    "\n",
    "    # Count ingredients per level\n",
    "    level_counts = df[\"Level\"].value_counts()\n",
    "\n",
    "    print(\"\\nIngredient Counts by Level:\")\n",
    "    print(level_counts)\n",
    "\n",
    "    print(\"\\nExtracted Data:\")\n",
    "    print(df)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    output_path = \"/Users/ireneliu/Desktop/ingredients_analysis.csv\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to {output_path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72e13b2-c85d-4aee-a51c-2e6b7eb2290c",
   "metadata": {},
   "source": [
    "# Load Ingredient Data From The CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c95b25-caaf-4e64-aba3-3c6181af0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ingredient levels from CSV...\n",
      "Loaded ingredient levels:\n",
      "{'LEVEL 1': ['Sunflower Oil', 'Blue #1', 'Cheese (swiss)', 'Blue #2', 'Yogurt (plain Greek)', 'Yellow #5', 'Yogurt (plain)', 'Yellow #6', 'Almond Oil', 'Apple', 'Beef Fat', 'Canola Oil', 'Blueberries', 'Hemp Seed Oil', 'Mango', 'Oranges', 'Salmon Oil', 'Sardine Oil', 'Pears', 'Sesame Oil', 'Pineapples', 'Soybean Oil', 'Raspberries', 'Pet Standard', 'Ground Yellow Corn', 'Pearled Barley', 'Gelatin', 'Quinoa', 'Hemp', 'Quinoa Powder', 'Rice (brown)', 'Lactobacillus Acidophilus', 'Rice (white)', 'Soy Grits', 'Yeast', 'Bison', 'Canola Meal', 'Chicken Heart', 'Duck Gizzard', 'Bacon', 'Duck Liver', 'Duck Meal', 'Beef Broth', 'Beef Hide', 'Turkey Broth', 'Pork Skins', 'Crab', 'Rabbit Liver', 'Herring', 'Herring Meal', 'Lobster', 'Parsley', 'Sage', 'Oyster', 'Shrimp', 'Agar Gum', 'Calcium Chloride', 'Basil', 'Calcium Pantothenate', 'Calcium Sulfate', 'Fenugreek Seed', 'Carnitine', 'Zinc Sulfate', 'Copper Sulfate', 'E 306 Natural Tocopherols (vitamin E)', 'Dicalcium Phosphate', 'E 307 Alpha-Tocopherol', 'Ferrous Sulfate', 'E 308 Synthetic Gamma-Tocopherol', 'Folic Acid', 'E 309 Synthetic Delta-Tocopherol', 'Asparagus', 'Guar Gum', 'Beans (black)', 'Inositol', 'Beans (chickpea)', 'Inulin', 'Beans (green)', 'Beets', 'Carrots', 'Celery'], 'LEVEL 2': ['Cheese (cheddar)', 'Milk (cow)', 'Caramel Color', 'Milk (goat)', 'Red #40', 'Chicken Fat', 'Coconut Oil', 'Cod Liver Oil', 'Figs', 'Honeydew Melon', 'Herring Oil', 'Pork Fat', 'Tomato Pomace', 'Wheat Middlings', 'Watermelons', 'Corn Meal', 'Barley Grass', 'Flaxseed', 'Bee Pollen', 'Brewers Yeast', 'Millet', 'Catnip', 'Oat', 'Pea Fiber', 'Rice Flour', 'Psyllium Seed Husk', 'Spirulina', 'Wheat Flour', 'Yeast Culture', 'Bison Meal', 'Bone Meal', 'Peanuts', 'Chicken By Product', 'Sunflower Seeds', 'Chicken Liver', 'Chicken Meal', 'Egg White (chicken)', 'Beef Heart', 'Beef Liver', 'Egg Yolk (quail)', 'Pet Standard', 'Elk', 'Soy Protein Concentrate', 'Goat', 'Goose', 'Soybean Meal', 'Kangaroo', 'Turkey', 'Lamb', 'Lamb Meal', 'Turkey Gizzard', 'Pea Protein', 'Turkey Heart', 'Veal', 'Pheasant Liver', 'Pork', 'Venison Meal', 'Pork Heart', 'Anchovy', 'Pork Kidney', 'Anchovy Meal', 'Pork Liver', 'Mackerel', 'Parsley Flakes', 'Menhaden Fish Meal', 'Rosemary', 'Mussels', 'Rosemary Extract', 'Salmon Meal', 'Sardine Meal', 'Sucrose', 'Sea Bass', 'Sole', 'Ascorbic Acid', 'Tilapia', 'Biotin', 'Trout', 'Calcium Carbonate', 'Tuna', 'Calcium Iodate', 'Cilantro', 'Glucosamine Hydrochloride', 'Lecithins', 'Niacin', 'Phosphoric Acid', 'Chicory Root', 'Sodium Chloride', 'Chicory Root Extract', 'Sodium Selenate', 'Taurine', 'Dandelion Greens', 'Greens (collard)', 'Pumpkin', 'Squash (butternut)', 'Yam'], 'LEVEL 3': ['Vegetable Oil', 'Cheese (cottage)', 'Bananas', 'Cantaloupe', 'Cranberries', 'Kiwis', 'Olive Oil', 'Peaches', 'Strawberries', 'Wheat Gluten', 'Whole Grain Sorghum', 'Barley', 'Alfalfa', 'Brewers Rice', 'Alfalfa (dehydrated)', 'Chia Seeds', 'Oat Groats', 'Chlorella', 'Kelp', 'Rice Bran', 'Potato Flour', 'Potato Starch', 'Rye', 'Powdered Cellulose', 'Soy Flour', 'Tapioca', 'Pet Standard', 'Tapioca Starch', 'Beef Meal', 'Vinegar (apple cider)', 'Beef Tallow', 'Yucca Schidigera Extract', 'Almond', 'Cashew Nuts', 'Chicken', 'Peanut Butter', 'Chicken Broth', 'Alfalfa Meal Concentrate', 'Alfalfa Nutrient Concentrate', 'Alligator', 'Duck', 'Alligator Meal', 'Beef', 'Egg White (duck)', 'Egg White (quail)', 'Beef Jerky', 'Egg Yolk (chicken)', 'Beef Kidney', 'Egg Yolk (duck)', 'Soy Protein Isolate', 'Pheasant', 'Turkey Liver', 'Pheasant Gizzard', 'Turkey Meal', 'Pheasant Heart', 'Venison', 'Catfish', 'Pork Meal', 'Catfish Meal', 'Quail', 'Fish Broth', 'Rabbit', 'Fish Meal', 'Rabbit Heart', 'Halibut', 'Rabbit Meal', 'Ocean Fish Meal', 'Thyme', 'Salmon', 'Turmeric', 'High Fructose Corn Syrup', 'Sardine', 'Honey', 'Sugar (brown)', 'Whitefish Meal', 'Ginger', 'Carrageenan', 'Oregano Powder', 'Choline Chloride', 'Citric Acid', 'Manganese Proteinate', 'Bok Choy', 'Manganese Sulfate', 'Broccoli', 'Brussels Sprouts', 'Omega 3 Fatty Acid', 'Cabbage', 'Potassium Chloride', 'Cauliflower', 'Pyridoxine Hydrochloride', 'Riboflavin', 'Corn', 'Soy Lecithin', 'Cucumber', 'Lentils', 'Spinach', 'Peas', 'Potato (yellow)', 'Squash (zucchini)', 'Potatoes (sweet)', 'Potatoes (white)']}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_levels_from_csv(csv_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Initialize LEVELS dictionary\n",
    "    levels = {}\n",
    "\n",
    "    # Extract unique levels and their associated ingredients\n",
    "    for level in df[\"Level\"].unique():\n",
    "        # Filter rows belonging to the current level\n",
    "        ingredients = df[df[\"Level\"] == level][\"Ingredient\"].dropna().unique()\n",
    "        # Add to levels dictionary\n",
    "        levels[level] = list(ingredients)\n",
    "    \n",
    "    return levels\n",
    "\n",
    "# Function to analyze ingredients\n",
    "def analyze_ingredients(data, levels):\n",
    "    results = []\n",
    "    for item in data:\n",
    "        name = item[\"name\"]\n",
    "        brand = item[\"brand\"]\n",
    "        ingredients = item[\"ingredients\"]\n",
    "        \n",
    "        level_counts = {level: 0 for level in levels}\n",
    "        for level, keywords in levels.items():\n",
    "            for keyword in keywords:\n",
    "                level_counts[level] += len(re.findall(re.escape(keyword), ingredients, re.IGNORECASE))\n",
    "        \n",
    "        results.append({\n",
    "            \"brand\": brand,\n",
    "            \"name\": name,\n",
    "            **level_counts\n",
    "        })\n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the CSV file\n",
    "    csv_path = \"/Users/ireneliu/Desktop/ingredients_analysis.csv\"\n",
    "\n",
    "    print(\"Loading ingredient levels from CSV...\")\n",
    "    LEVELS = load_levels_from_csv(csv_path)\n",
    "    print(\"Loaded ingredient levels:\")\n",
    "    print(LEVELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7192e386-d03c-4245-975a-e1a00cb6570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4 pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d282da4-a17a-4f5f-9985-de5798a0c432",
   "metadata": {},
   "source": [
    "#  API For Dog Food Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e12e018-6412-4119-889e-96f78cdbd8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Brand  \\\n",
      "0                Royal Canin   \n",
      "1                              \n",
      "2          Canine Carry Outs   \n",
      "3          Canine Carry Outs   \n",
      "4     Instinct the raw brand   \n",
      "..                       ...   \n",
      "78  Heart to Tail,Pure Being   \n",
      "79     Fromm Family Pet Food   \n",
      "80  Pure Balance Small Breed   \n",
      "81                Farm Table   \n",
      "82                    purina   \n",
      "\n",
      "                                          Ingredients  \n",
      "0                                                 N/A  \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4   chicken(including ground chicken bone),beef li...  \n",
      "..                                                ...  \n",
      "78  deboned salmon, chicken meal, sweet potatoes, ...  \n",
      "79  Chicken, Chicken Meal, Chicken Broth, Oat Groa...  \n",
      "80  chicken, chicken meal, dried ground peas, tapi...  \n",
      "81                                                N/A  \n",
      "82                                                N/A  \n",
      "\n",
      "[83 rows x 2 columns]\n",
      "Data saved to 'dog_food_ingredients.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_url = \"https://us.openpetfoodfacts.org/cgi/search.pl\"\n",
    "\n",
    "# Parameters for the API request\n",
    "params = {\n",
    "    'search_terms': 'dog food',\n",
    "    'search_simple': 1,\n",
    "    'action': 'process',\n",
    "    'json': 1,\n",
    "    'page_size': 100  \n",
    "}\n",
    "\n",
    "# Send GET request to the API\n",
    "response = requests.get(api_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    products = data.get('products', [])\n",
    "\n",
    "    # Extract brand names and ingredients\n",
    "    product_info = []\n",
    "    for product in products:\n",
    "        brand = product.get('brands', 'N/A')  # Extract the brand name\n",
    "        ingredients = product.get('ingredients_text', 'N/A')  # Extract the ingredients\n",
    "        product_info.append({'Brand': brand, 'Ingredients': ingredients})\n",
    "\n",
    "    # Convert to DataFrame for better readability\n",
    "    df = pd.DataFrame(product_info)\n",
    "    print(df)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv('dog_food_ingredients.csv', index=False)\n",
    "    print(\"Data saved to 'dog_food_ingredients.csv'\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd6c8b6-8079-47cf-a7e9-aa01e874d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names:\n",
      "Index(['_id', '_keywords', 'added_countries_tags', 'additives_old_tags',\n",
      "       'additives_original_tags', 'additives_tags', 'allergens',\n",
      "       'allergens_from_ingredients', 'allergens_from_user',\n",
      "       'allergens_hierarchy',\n",
      "       ...\n",
      "       'nutrition_data_per_debug_tags', 'origins_debug_tags',\n",
      "       'packaging_debug_tags', 'product_name_debug_tags',\n",
      "       'product_name_fr_debug_tags', 'purchase_places_debug_tags',\n",
      "       'serving_size_debug_tags', 'stores_debug_tags', 'traces_debug_tags',\n",
      "       'quality_tags'],\n",
      "      dtype='object', length=278)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "api_url = \"https://us.openpetfoodfacts.org/cgi/search.pl\"\n",
    "\n",
    "params = {\n",
    "    'search_terms': 'dog food',\n",
    "    'search_simple': 1,\n",
    "    'action': 'process',\n",
    "    'json': 1,\n",
    "    'page_size': 100  \n",
    "}\n",
    "\n",
    "response = requests.get(api_url, params=params)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    products = data.get('products', [])\n",
    "    \n",
    "    # Convert the raw data to a DataFrame\n",
    "    df = pd.DataFrame(products)\n",
    "    \n",
    "    # Display the column names\n",
    "    print(\"Column Names:\")\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a707bad-4a11-4116-8862-53edeaf87143",
   "metadata": {},
   "source": [
    "# Analyze Ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9178c9-870c-4521-b796-44c2bad659ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
